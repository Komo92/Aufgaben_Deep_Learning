{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "secret-issue",
   "metadata": {},
   "source": [
    "# Übung 1 - Aufgabe 1 - Erkennung von Mode\n",
    "\n",
    "Wird eine neue Programmiersprache erlernt, so beginnt man meistens mit einem *Hello World*. Im Bereich der KI bzw. des maschinellen Lernens wird gerne der *[MNIST Datensatz](https://de.wikipedia.org/wiki/MNIST-Datenbank)* als Beispiel verwendet. In dieser Aufgabe soll der sehr ähnlich aufgebaute *[Fashion-MNIST-Datensatz](https://github.com/zalandoresearch/fashion-mnist)* verwendet werden, um Modeartikel zu kategorisieren.\n",
    "\n",
    "Diese Aufgabe ist folgendermaßen aufgebaut:\n",
    "\n",
    "1. Vornehmen nötiger Imports\n",
    "2. Laden der Daten\n",
    "3. Aufbau des neuronalen Netzes\n",
    "4. Anlegen des neuronalen Netzes und der Trainingsumgebung\n",
    "5. Training und Test des neuronalen Netzes\n",
    "\n",
    "Sie werden im Verlauf Ihrer KI-Karriere sehr schnell feststellen, dass nahezu alle Projekte im maschinellen Lernen (mit Ergänzung weiterer Datenvorverarbeitung) diesen groben Aufbau verfolgen. Nehmen Sie bitte die nötigen Ergänzungen in den Zellen vor. Zum Experimentieren können Sie auch gerne weitere Codezellen hinzufügen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "active-elder",
   "metadata": {},
   "source": [
    "## 1. Nötige Imports vornehmen\n",
    "\n",
    "Die folgende Code-Zelle importiert die notwendigen Bibliotheken, die im Folgenden benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-cleaner",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: import: command not found\n",
      "bash: import: command not found\n",
      "bash: import: command not found\n",
      "bash: from: command not found\n",
      "bash: import: command not found\n",
      "bash: import: command not found\n",
      "bash: import: command not found\n",
      "bash: from: command not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "helpful-bahamas",
   "metadata": {},
   "source": [
    "## 2. Trainingsdaten laden\n",
    "\n",
    "Zunächst werden die Trainingsdaten aus dem Internet geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-reconstruction",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_set = datasets.FashionMNIST(root=\"\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_set = datasets.FashionMNIST(root=\"\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "atlantic-recruitment",
   "metadata": {},
   "source": [
    "Am Anfang sollen nur die ersten 500 Datensätze der Trainingsdaten ausgewählt werden. Damit geht das Training deutlich schneller, aber dieses Vorgehen hat auch Nachteile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-google",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "train_set.data = train_set.data[0:500] # Hier die ersten 500 Datensätze der Traningsdaten auswählen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "helpful-japanese",
   "metadata": {},
   "source": [
    "### 2.1. \"Form\" der Trainingsdaten betrachten\n",
    "\n",
    "Es wird nun die Form der Traningsdaten betrachtet. Haben Sie die vorherige Zelle korrekt ergänzt, so sollten Sie folgende Ausgabe erhalten:\n",
    "\n",
    "```\n",
    "train_set shape:  torch.Size([500, 28, 28])\n",
    "test_set shape:  torch.Size([10000, 28, 28])\n",
    "```\n",
    "\n",
    "Machen Sie sich nun bitte klar, was die Zahlen bedeuten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-audience",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"train_set shape: \", train_set.data.shape)\n",
    "print(\"test_set shape: \", test_set.data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28640477",
   "metadata": {},
   "source": [
    "Die Daten werden nun einem Data Loader übergeben, welcher eine Zufallsverteilung und eine Organisation in \"batches\" vornimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-ceremony",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, pin_memory=True, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "indirect-enterprise",
   "metadata": {},
   "source": [
    "### 2.2. Trainingsbeispiele ansehen\n",
    "\n",
    "Die folgende Zelle lädt die ersten Trainingsdaten und zeigt ein paar Beispiele für verschiedene Klassen an. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-coalition",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Erste Batch von Daten laden\n",
    "    break\n",
    "    \n",
    "figure = plt.figure()\n",
    "num_images = 18\n",
    "for i in range(num_images):\n",
    "    plt.subplot(3, 6, i+1, title=f\"{labels[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(images[i].cpu().numpy().squeeze(), cmap=\"gray_r\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "julian-version",
   "metadata": {},
   "source": [
    "## 3. Aufbau des neuronalen Netzes\n",
    "\n",
    "Jetzt wird das neuronale Netz definiert. Zunächst soll mit folgendem einfachen Aufbau begonnen werden:\n",
    "\n",
    "- Eine Eigabeschicht, die die $28 \\cdot 28$ Pixel auf eine **versteckte Schicht** abbildet.\n",
    "  Diese versteckte Schicht hat `hidden_size` Neuronen. Es wird mit zwei Neuronen \n",
    "  (`hidden_size = 2`) begonnen. \n",
    "- Die Eingabeschicht verwendet als **Aktivierungsfunktion** die \n",
    "  *[Rectified Linear Unit (ReLU)](https://de.wikipedia.org/wiki/Rectifier_(neuronale_Netzwerke))*\n",
    "- Eine **Ausgabeschicht**, die für jede mögliche Ziffer ein Neuron enthält.\n",
    "  Hier wird keine Aktivierungsfunktion benötigt – das am \"stärksten feuernde\" Neuron gewinnt am Ende\n",
    "  bzw. die Werte werden automatisch so normiert, dass sie zwischen $0$ und $1$ liegen und in der Summe \n",
    "  $1$ ergeben ([Softmax](https://de.wikipedia.org/wiki/Softmax-Funktion)).\n",
    "  \n",
    "Zur Definition des Netzes wird eine Funktion `__init__()` zur Initialisierung der Layer und eine \n",
    "Funktion `forward()` die Rechenschritte des Netzes ausführt benötigt. Den ganzen mathematischen Rest erledigt die Bibliothek *PyTorch*. Bitte ergänzen Sie die genannte Definion in der Klasse ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-nature",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "hidden_size = 2\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        # Hier die Intialiserung der Layer vornehmen\n",
    "        self.input_layer = nn.Linear(28*28, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hier die Rechenschritte des Netzes ergänzen\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        out = self.output_layer(x)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "tribal-blond",
   "metadata": {},
   "source": [
    "## 4. Neuronales Netz, Verlustfunktion und Optimierer anlegen\n",
    "\n",
    "Neben dem neuronalen Netz werden jetzt folgende Punkte erzeugt:\n",
    "- Die Verlustfunktion, die optimiert wird. Sie misst, ob das Netz die richtige Ziffer vorhersagt \n",
    "  und sich dabei möglichst sicher ist. Das heißt\n",
    "  - die Ausgabe des Neurons der vorliegenden Ziffer soll möglichst hoch,\n",
    "  - die Ausgabe der anderen Neuronen möglichst klein sein.\n",
    "  Dafür verwendet man die sogenannte *[Kreuzentropie](https://de.wikipedia.org/wiki/Kreuzentropie)* \n",
    "  (engl. *Cross Entropy*).\n",
    "- Den Optimierer, der beim Training die Verlustfunktion optimiert. Es soll `optim.SGD` verwendet werden, wobei   \n",
    "  *SGD* für *Stochastic Gradient Descent* steht. Anschaulich gesprochen verhält sich dieser Optimierer\n",
    "  wie ein Skifahrer im Nebel – er fährt einfach dalang, wo es bergab geht, und hofft, dass er heil \n",
    "  im Tal ankommt.\n",
    "  \n",
    "Ergänzen Sie nun die Initialiserung des Netzes, der Verlustfunktion und des Optimierers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-logistics",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Hier Initialiserung des Netzes vornehmen\n",
    "model = ANN()\n",
    "# Hier Initialiserung der Verlustfunktion vornehmen\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Hier Initialiserung des Optimierers vornehmen\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "after-election",
   "metadata": {},
   "source": [
    "Die Anzahl der Parameter im Model kann nun mit folgender Zeile überprüft werden. Haben Sie alles korrekt definiert, so sollten Sie hier 1600 Parameter erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-transcript",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wooden-hampton",
   "metadata": {},
   "source": [
    "## 5. Training des Modells\n",
    "\n",
    "Schließlich kann das Netz mit den Trainingsdaten trainiert werden. Jeder Durchlauf über die kompletten Trainingsdaten wird als *Epoche* bezeichnet.\n",
    "\n",
    "Da nur wenige Trainingsbilder verwendet werden, soll das Model viele Epochen trainieren (`epochs = 500`). \n",
    "\n",
    "**Achtung:** Wenn die Zahl der Trainingsbilder erhöht wird, sollte die Zahl der Epochen reduziert werden, weil das Training sonst sehr lange dauert!\n",
    "\n",
    "Ergänzen Sie nun die Ausführung des Trainings und Tests in der folgenden Zelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-discipline",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "testing_loss = []\n",
    "training_acc = []\n",
    "testing_acc = []\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "with tqdm(range(epochs)) as iterator:\n",
    "\n",
    "    for epoch in iterator:\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            # Hier die Ausführung des Trainings einer einzelnen Batch ergänzen\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        training_acc.append(train_acc/len(train_set))\n",
    "        training_loss.append(train_loss/len(train_set))\n",
    "\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                # Hier die Ausführung des Tests einer einzelnen Batch ergänzen\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        testing_acc.append(test_acc/len(test_set))\n",
    "        testing_loss.append(test_loss/len(test_set))\n",
    "        \n",
    "        iterator.set_postfix_str(f\"train_acc: {train_acc/len(train_set):.2f} test_acc: {test_acc/len(test_set):.2f} train_loss: {train_loss/len(train_set):.2f} test_loss: {test_loss/len(test_set):.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "governmental-rainbow",
   "metadata": {},
   "source": [
    "Am Ende lässt sich die Lernekurve des Modells sehen. **Sollte diese noch steigen, kann das Modell weiter trainiert werden, indem  die Zelle noch einmal aufgerufen wird.**\n",
    "\n",
    "Die folgenden beiden Zellen geben die Lernkurven aus und zeigen die *Genauigkeit* und den *Verlust* jeweils für die Trainings- und Testdaten an.\n",
    "\n",
    "**Was fällt beim Vergleich der Kurven für Test- und Trainingsadten auf?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-subscription",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.plot(range(epochs), training_acc, label=\"train_acc\")\n",
    "plt.plot(range(epochs), testing_acc, label=\"test_acc\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scilab",
   "language": "scilab",
   "name": "scilab"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "scilab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
