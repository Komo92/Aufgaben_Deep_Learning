{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "secret-issue",
   "metadata": {},
   "source": [
    "# Übung 2 - Aufgabe 1 - Klassifikation von Katzen und Hunden\n",
    "\n",
    "In dieser Aufgabe soll der im Buch vorgestellte Datensatz verwendet werden, um Katzen und Hunde zu klassifizieren. Im Gegensatz zur vorherigen Aufgabe soll in dieser allerdings mittels fortgeschritteneren Netzen klassifiziert werden. Verwenden Sie dazu CNNs folgender Typen:\n",
    "\n",
    "- Ein eigenes CNN angelehnt an das aus dem Buch\n",
    "- Ein VGG Ihrer Wahl\n",
    "- Ein ResNet Ihrer Wahl\n",
    "\n",
    "Verwenden Sie zusätzlich ein Netz auf Basis von Vision Transformern. Vergleichen Sie die Ergebnisse. Gehen Sie auf diese Weise vor ist es sinnvoll sich für das Training eine wiederverwendbare Funktion zu schreiben.\n",
    "\n",
    "Diese Aufgabe ist folgendermaßen aufgebaut:\n",
    "\n",
    "1. Vornehmen nötiger Imports\n",
    "2. Laden der Daten\n",
    "3. Definition des eigenen CNN\n",
    "4. Anlegen der neuronalen Netze\n",
    "5. Training und Tests der neuronalen Netze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "active-elder",
   "metadata": {},
   "source": [
    "## 1. Nötige Imports vornehmen\n",
    "\n",
    "Die folgende Code-Zelle importiert die notwendigen Bibliotheken, die im Folgenden benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-cleaner",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import timm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "helpful-bahamas",
   "metadata": {},
   "source": [
    "## 2. Trainingsdaten laden\n",
    "\n",
    "Zunächst werden die Trainingsdaten aus dem Verzeichnis geladen. Hierbei können Sie wie im Buch beschrieben vorgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-reconstruction",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "path = 'Data/'\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(root=path + 'train', transform=transform)\n",
    "valid_set = ImageFolder(root=path + 'valid', transform=transform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28640477",
   "metadata": {},
   "source": [
    "Im Folgenden kann eines der Bilder angezeigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15376a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "\n",
    "imshow(train_set[30][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb0bd1f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Daten werden nun einem Data Loader übergeben, welcher eine Zufallsverteilung und eine Organisation in \"batches\" vornimmt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512968b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,shuffle=True,batch_size=64,num_workers=0)\n",
    "valid_loader = DataLoader(valid_set,batch_size=64,num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7ab4aab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Definition des eigenen CNN\n",
    "\n",
    "Nutzen Sie die vorgegebene Klasse CNN, um ein eigenes CNN zu implementieren. Aufgrund der Größe der Eingabebilder, sollte dieses mindestens 4-5 Conv2D-Schichten enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd70026",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128*16*16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "julian-version",
   "metadata": {},
   "source": [
    "## 4. Anlegen der neuronalen Netze\n",
    "\n",
    "Legen Sie in der nächsten Zelle die vier Netze der vorgegebenen Typen an. Denken Sie daran die Ausgabe auf die Anzahl der vorliegenden Klassen anzupassen. Beim VGG lässt sich dies im letzten Layer der Sequenz \"classifier\" und beim Vision Transformer im letzten Layer der Sequenz \"heads\" setzen. Das ResNet können Sie wie im Kapitel 3 beschrieben anpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-nature",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_vgg(model, n_classes):\n",
    "    model.classifier[6] = nn.Linear(4096, n_classes)\n",
    "    return model\n",
    "\n",
    "def prepare_resnet(model, n_classes):\n",
    "    model.fc = nn.Linear(model.fc.in_features, n_classes)\n",
    "    return model\n",
    "\n",
    "def prepare_vit(model, n_classes):\n",
    "    # Angenommen, der Vision Transformer hat einen \"head\" oder \"classifier\" am Ende\n",
    "    # Sie müssen dies entsprechend dem von Ihnen verwendeten Modell anpassen.\n",
    "    model.head = nn.Linear(model.head.in_features, n_classes)\n",
    "    return model\n",
    "\n",
    "cnn = CNN()\n",
    "vgg = prepare_vgg(models.vgg16(pretrained=True), num_classes)\n",
    "resnet = prepare_resnet(models.resnet18(pretrained=True), num_classes)\n",
    "\n",
    "# Für den Vision Transformer:\n",
    "# Sie müssen ein Modell initialisieren, bevor Sie es verwenden können. \n",
    "# Hier habe ich es als `vit_model` bezeichnet. \n",
    "# Sie können eine Bibliothek wie `timm` verwenden, um ein vorab trainiertes Vision Transformer Modell zu erhalten.\n",
    "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "vit = prepare_vit(vit_model, num_classes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wooden-hampton",
   "metadata": {},
   "source": [
    "## 5. Training des Modells\n",
    "\n",
    "Schreiben Sie in die Funktion \"train_model\" die Trainingslogik der neuronalen Netze. Hier können Sie ähnlich wie bei der MNIST-Aufgabe vorgehen. Die Funktion \"plot_results\" kann Genauigkeit und Verlust als Plot darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-discipline",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(epochs, training_acc, testing_acc, training_loss, testing_loss):\n",
    "    plt.plot(range(epochs), training_acc, label=\"train_acc\")\n",
    "    plt.plot(range(epochs), testing_acc, label=\"valid_acc\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(epochs), training_loss, label=\"train_loss\")\n",
    "    plt.plot(range(epochs), testing_loss, label=\"valid_loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model, epochs=10, learning_rate=0.001):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_loss = []\n",
    "    testing_loss = []\n",
    "    training_acc = []\n",
    "    testing_acc = []\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "\n",
    "    with tqdm(range(epochs)) as iterator:\n",
    "        for epoch in iterator:\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = images.to(\"cuda\")\n",
    "                    labels = labels.to(\"cuda\")\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_acc += (predicted == labels).sum().item()\n",
    "\n",
    "            training_acc.append(train_acc/len(train_set))\n",
    "            training_loss.append(train_loss/len(train_loader))\n",
    "\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in valid_loader:\n",
    "                    if torch.cuda.is_available():\n",
    "                        images = images.to(\"cuda\")\n",
    "                        labels = labels.to(\"cuda\")\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "\n",
    "                    test_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    test_acc += (predicted == labels).sum().item()\n",
    "\n",
    "                testing_acc.append(test_acc/len(valid_set))\n",
    "                testing_loss.append(test_loss/len(valid_loader))\n",
    "\n",
    "            iterator.set_postfix_str(f\"train_acc: {train_acc/len(train_set):.2f} test_acc: {test_acc/len(valid_set):.2f} train_loss: {train_loss/len(train_loader):.2f} test_loss: {test_loss/len(valid_loader):.2f}\")\n",
    "\n",
    "    plot_results(epochs, training_acc, testing_acc, training_loss, testing_loss)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9904449",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wenn Sie Ihre Funktion \"train_model\" korrekt implementiert haben und Ihre Modelle definiert sind, können Sie ihre Modelle in den folgenden vier Zellen trainieren lassen. Da der Datensatz recht groß ist, würde ich ein Training auf 3-10 Epochen begrenzen. Falls Sie eine Cuda-fähige Grafikkarten besitzen, können Sie auch länger trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35555653",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_model(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b9321",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_model(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-subscription",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_model(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-observer",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_model(vit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scilab",
   "language": "scilab",
   "name": "scilab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "scilab",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
